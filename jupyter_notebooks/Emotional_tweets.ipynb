{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "\n",
    "basename = \"/home/adrian/PhD/Tweet-Classification-Diabetes-Distress/\"\n",
    "path_utils = op.join(basename , \"utils\")\n",
    "sys.path.insert(0, path_utils)\n",
    "\n",
    "from sys_utils import load_library\n",
    "from tweet_utils import tweet_vectorizer\n",
    "from defines import Patterns, Emotions\n",
    "from emotion_codes import UNICODE_EMOJI, EMOJI_TO_CATEGORY\n",
    "from preprocess import Preprocess\n",
    "prep = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'created_at', 'lang', 'text', 'user_name', 'user_screen_name',\n",
      "       'user_followers_count', 'user_friends_count', 'user_location',\n",
      "       'user_description', 'place_full_name', 'retweeted_user_name',\n",
      "       'retweeted_user_screen_name', 'retweeted_user_followers_count',\n",
      "       'retweeted_user_friends_count', 'retweeted_user_location',\n",
      "       'retweeted_user_description', 'retweeted_place_full_name',\n",
      "       'retweeted_text', 'posted_month', 'tweet_URL_USER', '__index_level_0__',\n",
      "       '__index_level_1__', 'geo_id', 'geo_name', 'geo_code', 'geo_type',\n",
      "       'geo_country_code', 'geo_city_code', 'geo_adm1_code', 'geo_adm2_code',\n",
      "       'geo_adm3_code', 'geo_adm4_code', 'pop', '_score_', '_tags_',\n",
      "       '_startIndex_', '_endIndex_'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_city_code</th>\n",
       "      <th>geo_adm1_code</th>\n",
       "      <th>geo_adm2_code</th>\n",
       "      <th>geo_adm3_code</th>\n",
       "      <th>geo_adm4_code</th>\n",
       "      <th>pop</th>\n",
       "      <th>_score_</th>\n",
       "      <th>_tags_</th>\n",
       "      <th>_startIndex_</th>\n",
       "      <th>_endIndex_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.675721e+17</td>\n",
       "      <td>Thu May 25 02:44:51 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>@kristilade It doesn't suck. I have it. It wor...</td>\n",
       "      <td>Wil Gentry</td>\n",
       "      <td>wilable70</td>\n",
       "      <td>926.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Be yourself. No on else wants to be you.</td>\n",
       "      <td>...</td>\n",
       "      <td>5809844</td>\n",
       "      <td>WA</td>\n",
       "      <td>033</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.545088</td>\n",
       "      <td>221.237152</td>\n",
       "      <td>Seattle,WA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.129140e+18</td>\n",
       "      <td>Thu May 16 21:42:52 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>When I was initially diagnosed with #type2diab...</td>\n",
       "      <td>Lynda Jimenez</td>\n",
       "      <td>lyndajimenez22</td>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Boymom living with LADA #diabetes.  Employee a...</td>\n",
       "      <td>...</td>\n",
       "      <td>5308655</td>\n",
       "      <td>AZ</td>\n",
       "      <td>013</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.626851</td>\n",
       "      <td>262.320343</td>\n",
       "      <td>Phoenix,AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.102559e+18</td>\n",
       "      <td>Mon Mar 04 13:17:40 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>Later Twitter it's back to sleep for a nap wok...</td>\n",
       "      <td>Deanna Porter Weick</td>\n",
       "      <td>deanna_weick</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>Monroe, MI</td>\n",
       "      <td>Native American Potowatomi adopted out  raised...</td>\n",
       "      <td>...</td>\n",
       "      <td>5002344</td>\n",
       "      <td>MI</td>\n",
       "      <td>115</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.231201</td>\n",
       "      <td>225.749695</td>\n",
       "      <td>Monroe,MI</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.087817e+18</td>\n",
       "      <td>Tue Jan 22 20:58:04 +0000 2019</td>\n",
       "      <td>en</td>\n",
       "      <td>Please read this! There are people dying becau...</td>\n",
       "      <td>BTSARMYMOM</td>\n",
       "      <td>cure4t1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>Mom, Music lover, BTS ARMY member (thanks to m...</td>\n",
       "      <td>...</td>\n",
       "      <td>4533580</td>\n",
       "      <td>OK</td>\n",
       "      <td>131</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.227495</td>\n",
       "      <td>133.306839</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.641931e+17</td>\n",
       "      <td>Mon May 15 18:57:38 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>My stepson was 4 or 5. Damn you kids with your...</td>\n",
       "      <td>Writing as I Go</td>\n",
       "      <td>WritingAsIGo</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>Colorado Springs, Colorado</td>\n",
       "      <td>Starting the job hunt again. Book Reviewer whi...</td>\n",
       "      <td>...</td>\n",
       "      <td>5417598</td>\n",
       "      <td>CO</td>\n",
       "      <td>041</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.505316</td>\n",
       "      <td>322.702881</td>\n",
       "      <td>Colorado,Springs,Colorado</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                      created_at lang  \\\n",
       "0  8.675721e+17  Thu May 25 02:44:51 +0000 2017   en   \n",
       "1  1.129140e+18  Thu May 16 21:42:52 +0000 2019   en   \n",
       "2  1.102559e+18  Mon Mar 04 13:17:40 +0000 2019   en   \n",
       "3  1.087817e+18  Tue Jan 22 20:58:04 +0000 2019   en   \n",
       "4  8.641931e+17  Mon May 15 18:57:38 +0000 2017   en   \n",
       "\n",
       "                                                text            user_name  \\\n",
       "0  @kristilade It doesn't suck. I have it. It wor...           Wil Gentry   \n",
       "1  When I was initially diagnosed with #type2diab...        Lynda Jimenez   \n",
       "2  Later Twitter it's back to sleep for a nap wok...  Deanna Porter Weick   \n",
       "3  Please read this! There are people dying becau...           BTSARMYMOM   \n",
       "4  My stepson was 4 or 5. Damn you kids with your...      Writing as I Go   \n",
       "\n",
       "  user_screen_name  user_followers_count  user_friends_count  \\\n",
       "0        wilable70                 926.0              2920.0   \n",
       "1   lyndajimenez22                  30.0                70.0   \n",
       "2     deanna_weick                2222.0              2721.0   \n",
       "3          cure4t1                 122.0               840.0   \n",
       "4     WritingAsIGo                 485.0              1195.0   \n",
       "\n",
       "                user_location  \\\n",
       "0                 Seattle, WA   \n",
       "1                 Phoenix, AZ   \n",
       "2                  Monroe, MI   \n",
       "3                      Rogers   \n",
       "4  Colorado Springs, Colorado   \n",
       "\n",
       "                                    user_description  ... geo_city_code  \\\n",
       "0           Be yourself. No on else wants to be you.  ...       5809844   \n",
       "1  Boymom living with LADA #diabetes.  Employee a...  ...       5308655   \n",
       "2  Native American Potowatomi adopted out  raised...  ...       5002344   \n",
       "3  Mom, Music lover, BTS ARMY member (thanks to m...  ...       4533580   \n",
       "4  Starting the job hunt again. Book Reviewer whi...  ...       5417598   \n",
       "\n",
       "   geo_adm1_code  geo_adm2_code  geo_adm3_code  geo_adm4_code       pop  \\\n",
       "0             WA            033           None           None  1.545088   \n",
       "1             AZ            013           None           None  1.626851   \n",
       "2             MI            115           None           None  1.231201   \n",
       "3             OK            131           None           None  1.227495   \n",
       "4             CO            041           None           None  1.505316   \n",
       "\n",
       "      _score_                     _tags_  _startIndex_  _endIndex_  \n",
       "0  221.237152                 Seattle,WA             0           2  \n",
       "1  262.320343                 Phoenix,AZ             0           2  \n",
       "2  225.749695                  Monroe,MI             0           2  \n",
       "3  133.306839                     Rogers             0           1  \n",
       "4  322.702881  Colorado,Springs,Colorado             0           3  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_parquet(\"/home/adrian/PhD/Data/Tweets20190708/matching-tweets_diab_noRT-noBots_personal_noJokes_locationUS_geoCityCodeNotNull.parquet\", engine=\"pyarrow\")\n",
    "print(tweets.columns)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_emoticonEmoji_in_tweet(tweet):\n",
    "    \n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    \n",
    "    for word in tweet: \n",
    "        match_emoticon = Patterns.EMOTICONS_PATTERN.findall(word)\n",
    "        \n",
    "        # if emoticon found\n",
    "        if match_emoticon:\n",
    "            if match_emoticon[0] is not \":\" and match_emoticon[0] is not \")\":\n",
    "                if match_emoticon[0] == \":\" or match_emoticon[0] == \")\":\n",
    "                    print(tweet)\n",
    "                    print(match_emoticon[0])\n",
    "                    print()\n",
    "                return True\n",
    "            \n",
    "        # if emoji found    \n",
    "        if word in UNICODE_EMOJI: \n",
    "\n",
    "            emot_cat = EMOJI_TO_CATEGORY[UNICODE_EMOJI[word]]\n",
    "            if emot_cat != \"\": \n",
    "                if word == \":\" or word == \")\":\n",
    "                    print(tweet)\n",
    "                    print(word, emot_cat)\n",
    "                    print()\n",
    "                return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "def check_emotKeywords(tweet):\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = tweet.replace(\"nerve pain\", \"\")\n",
    "    tweet = tweet.replace(\"nerve damage\", \"\")\n",
    "    tweet = tweet.replace(\"pain of neuropathy\", \"\")\n",
    "    tweet = prep.to_lowercase(tweet)\n",
    "    tweet = [word for word in tweet if word not in [\"healthcare\"]]\n",
    "    \n",
    "    for word in tweet:\n",
    "        for emot in Emotions.emotions_full_list:\n",
    "            \n",
    "            if emot == word: \n",
    "                #print(tweet)\n",
    "                #print(emot)\n",
    "                #print()\n",
    "                return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "\n",
    "tweets[\"emotion\"] = tweets.text.map(lambda tweet: check_emoticonEmoji_in_tweet(tweet) or check_emotKeywords(tweet))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11218, 39)\n"
     ]
    }
   ],
   "source": [
    "emot_tweets = tweets[tweets[\"emotion\"] == True]\n",
    "print(emot_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@kristilade It doesn't suck. I have it. It works for me. I wouldn't have found out I have diabetes without it. Nowâ€¦ https://t.co/kHS8R9STVC\n",
      "False\n",
      "\n",
      "When I was initially diagnosed with #type2diabetes almost 10 years ago, I was in a dark place - blaming myself, feeâ€¦ https://t.co/pLtFgM2wKr\n",
      "False\n",
      "\n",
      "Later Twitter it's back to sleep for a nap woke up at 5:30am to let the puppies out. Took my diabetic meds had an eâ€¦ https://t.co/7TxMvXmEja\n",
      "True\n",
      "\n",
      "Please read this! There are people dying because they canâ€™t afford their insulin!\n",
      "False\n",
      "\n",
      "My stepson was 4 or 5. Damn you kids with your #type1diabetes and your rock and roll. https://t.co/sASXzNOG6Z\n",
      "False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in tweets[[\"text\", \"emotion\"]].head().iterrows():\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"emotion\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ðŸ˜‚', 1343), ('â¤', 1263), ('ðŸ˜­', 1202), ('ðŸ’™', 926), ('ðŸ™„', 804), (':)', 655), ('ðŸ˜©', 643), ('ðŸ™ƒ', 639), ('ðŸ˜', 411), (':(', 335), ('ðŸ˜¢', 314), ('ðŸ˜Š', 284), ('ðŸ˜”', 273), ('ðŸ˜’', 269), ('ðŸ˜¡', 262), ('dx', 229), ('ðŸ˜³', 226), ('ðŸ¤¢', 225), ('ðŸ’•', 225), ('ðŸ¤£', 221), ('ðŸ˜', 205), ('ðŸ˜ž', 201), ('ðŸ’œ', 178), ('ðŸ¤—', 166), (':3', 159), (':/', 156), ('â™¥', 152), ('ðŸ˜€', 138), ('ðŸ˜•', 135), ('ðŸ˜±', 129), ('ðŸ™‚', 127), ('ðŸ˜“', 121), ('ðŸ˜·', 119), ('ðŸ˜¥', 114), (';)', 102), ('â˜º', 96), ('ðŸ’–', 96), ('ðŸ˜¤', 94), ('ðŸ’—', 87), ('ðŸ˜ƒ', 86), (':-)', 86), ('ðŸ’‹', 73), (':D', 72), ('ðŸ˜„', 68), ('ðŸ˜˜', 68), ('):', 67), ('ðŸ™', 64), ('ðŸ˜†', 61), ('ðŸ˜°', 55), ('ðŸ’š', 55), ('ðŸ’›', 53), ('ðŸ˜‡', 52), ('ðŸ˜²', 49), ('ðŸ˜ ', 48), ('Dx', 48), ('ðŸ˜®', 41), ('ðŸ˜»', 40), ('ðŸ’“', 39), ('ðŸ˜¨', 37), ('ðŸ’ž', 36), ('ðŸ’©', 31), ('DX', 27), ('ðŸ˜µ', 26), ('ðŸ˜¯', 26), (':P', 24), ('(:', 22), ('0:3', 21), ('ðŸ’«', 20), ('XD', 19), ('ðŸ˜§', 17), ('ðŸ˜¿', 17), ('xD', 14), (':p', 11), ('ðŸ™€', 10), (\":')\", 10), (\":'(\", 10), ('dX', 9), ('=/', 9), (';D', 9), ('D:', 8), ('ðŸ˜º', 8), ('ðŸ˜¸', 8), ('xd', 7), ('ðŸ˜¹', 7), ('t.T', 7), ('=d', 6), ('ðŸ˜š', 6), ('ðŸ’Ÿ', 6), ('=D', 5), ('QQ', 5), (':]', 5), (';d', 5), (':|', 4), ('ðŸ˜½', 4), ('t.t', 4), ('ðŸ‘¿', 3), ('ðŸ˜—', 3), ('=)', 3), ('ðŸ˜™', 3), ('ðŸ’', 2), ('ðŸ˜¾', 2), ('D;', 2), (':[', 2), ('=p', 2), (':d', 2), ('8D', 2), ('>:(', 2), ('ðŸ’¢', 1), (':*', 1), ('=P', 1), ('d:', 1), (':o', 1), ('D=', 1), ('=\\\\', 1), ('D8', 1), ('=(', 1)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "emotico_dict = {}\n",
    "\n",
    "for tweet in tweets.text:\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    for word in tweet: \n",
    "        match_emoticon = Patterns.EMOTICONS_PATTERN.findall(word)\n",
    "        \n",
    "        # if emoticon found\n",
    "        if match_emoticon:\n",
    "            if match_emoticon[0] is not \":\" and match_emoticon[0] is not \")\":\n",
    "                if match_emoticon[0] in emotico_dict: emotico_dict[match_emoticon[0]] += 1\n",
    "                else : emotico_dict[match_emoticon[0]] = 1\n",
    "                \n",
    "        # if emoji found    \n",
    "        if word in UNICODE_EMOJI: \n",
    "            emot_cat = EMOJI_TO_CATEGORY[UNICODE_EMOJI[word]]\n",
    "            if emot_cat != \"\": \n",
    "                if word in emotico_dict: emotico_dict[word] += 1\n",
    "                else : emotico_dict[word] = 1\n",
    "                \n",
    "sorted_x = sorted(emotico_dict.items(), key=operator.itemgetter(1))[::-1]\n",
    "print(sorted_x)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 3704), ('love', 2434), ('feel', 2226), ('bad', 2016), ('care', 1826), ('hope', 1457), ('sick', 1049), ('happy', 994), ('understand', 958), ('hate', 901), ('pain', 815), ('amazing', 664), ('excited', 650), ('sad', 604), ('glad', 596), ('awesome', 544), ('shock', 479), ('worry', 477), ('depression', 469), ('alone', 415), ('poor', 404), ('Hope', 375), ('worried', 352), ('terrible', 310), ('funny', 300), ('fear', 300), ('anxiety', 294), ('horrible', 285), ('suffer', 269), ('stress', 263), ('attention', 254), ('loved', 241), ('hurt', 236), ('nerve', 227), ('awful', 226), ('enjoy', 214), ('surprised', 209), ('suffering', 207), ('crying', 206), ('beat', 201), ('broken', 193), ('cry', 185), ('shame', 178), ('angry', 174), ('nervous', 173), ('despite', 163), ('damage', 162), ('mad', 161), ('trouble', 152), ('cried', 151), ('outrageous', 142), ('fail', 141), ('upset', 141), ('affect', 135), ('refuse', 133), ('sensitive', 128), ('impact', 121), ('annoying', 113), ('catch', 112), ('trust', 112), ('concern', 111), ('terrifying', 111), ('pissed', 108), ('frustrating', 107), ('scare', 105), ('disgusting', 104), ('depressed', 100), ('exciting', 98), ('terrified', 96), ('shocked', 96), ('caring', 93), ('loving', 93), ('painful', 89), ('surprise', 89), ('joy', 87), ('promise', 86), ('ashamed', 86), ('appreciated', 78), ('panic', 75), ('emotional', 75), ('hurting', 74), ('frustrated', 72), ('worrying', 71), ('sadly', 70), ('stressed', 70), ('relief', 69), ('Depression', 63), ('fairly', 62), ('disappointed', 60), ('tend', 59), ('subject', 59), ('injury', 57), ('headache', 56), ('desperately', 56), ('amazed', 52), ('miserable', 50), ('desperate', 50), ('lecture', 50), ('anxious', 49), ('bother', 46), ('starve', 46), ('passion', 45), ('rage', 45), ('dark', 45), ('content', 44), ('guilty', 44), ('block', 43), ('annoyed', 43), ('bear', 43), ('horror', 43), ('screw', 42), ('infuriating', 42), ('pleasure', 41), ('hated', 41), ('abuse', 41), ('disgusted', 40), ('thrilled', 40), ('solid', 37), ('guilt', 37), ('rush', 37), ('horrific', 37), ('dislike', 36), ('moderate', 36), ('harm', 34), ('awkward', 34), ('compassion', 33), ('pathetic', 33), ('depressing', 32), ('shocking', 32), ('nerves', 32), ('desire', 31), ('anger', 31), ('excitement', 30), ('happiness', 30), ('rally', 30), ('outrage', 30), ('inflammation', 29), ('defeated', 29), ('lean', 29), ('jealous', 28), ('frustration', 28), ('moderation', 28), ('disappointing', 28), ('fascinating', 28), ('surprising', 27), ('trauma', 27), ('liking', 27), ('shake', 27), ('curse', 27), ('torture', 27), ('disgrace', 27), ('sweetness', 27), ('maintenance', 26), ('beloved', 26), ('unconscionable', 26), ('spite', 26), ('threat', 25), ('furious', 25), ('crush', 25), ('regret', 25), ('sympathy', 25), ('eliminate', 24), ('gladly', 24), ('victory', 24), ('embarrassed', 24), ('shameful', 23), ('grief', 23), ('horrifying', 23), ('embarrassing', 22), ('frightening', 22), ('exorbitant', 21), ('appalled', 21), ('outraged', 21), ('awe', 20), ('cheering', 20), ('dreaded', 20), ('disturbing', 20), ('outrageously', 20), ('appalling', 20), ('rejected', 20), ('bruise', 19), ('defeat', 19), ('madness', 19), ('celebration', 19), ('cranky', 18), ('ignored', 18), ('lonely', 18), ('cheer', 18), ('irritated', 17), ('happily', 17), ('dread', 17), ('pleasant', 16), ('satisfied', 16), ('pity', 16), ('substance', 16), ('tolerate', 15), ('sunshine', 15), ('grumpy', 15), ('isolated', 15), ('violence', 15), ('pinch', 15), ('horrendous', 14), ('optimistic', 14), ('sadness', 14), ('raging', 14), ('crave', 14), ('boot', 13), ('despise', 13), ('attractive', 13), ('satisfying', 13), ('terrific', 13), ('crushed', 13), ('sympathetic', 13), ('shamed', 13), ('square', 12), ('empathize', 12), ('humbled', 12), ('bitter', 12), ('curb', 12), ('dependency', 12), ('misery', 12), ('excruciating', 11), ('cushion', 11), ('distress', 11), ('panicked', 11), ('frightened', 11), ('fierce', 11), ('kindly', 11), ('dreadful', 11), ('unhappy', 11), ('spooky', 11), ('stunned', 11), ('cult', 11), ('pesky', 11), ('lover', 11), ('eager', 11), ('offend', 10), ('ecstatic', 10), ('yucky', 10), ('comforting', 10), ('queer', 10), ('grasp', 10), ('isolation', 9), ('horrid', 9), ('humbling', 9), ('endure', 9), ('separated', 9), ('hatred', 9), ('irritating', 9), ('disgraceful', 9), ('digest', 9), ('insecure', 9), ('neglect', 9), ('hopeless', 9), ('worrisome', 9), ('moody', 9), ('sufferer', 9), ('stranded', 8), ('maddening', 8), ('spoil', 8), ('harassed', 8), ('fearful', 8), ('scandal', 8), ('disregard', 8), ('inconvenience', 8), ('tease', 8), ('troubling', 8), ('stimulate', 8), ('loathe', 8), ('staggering', 8), ('amaze', 7), ('agonizing', 7), ('disappointment', 7), ('disposition', 7), ('resent', 7), ('sympathize', 7), ('flush', 7), ('discomfort', 7), ('understandable', 7), ('appealing', 7), ('astounding', 7), ('restless', 7), ('tension', 7), ('spice', 7), ('beautifully', 7), ('extortionate', 7), ('brace', 7), ('horrified', 7), ('attendant', 6), ('delighted', 6), ('astounded', 6), ('disrespect', 6), ('amused', 6), ('leaning', 6), ('grieve', 6), ('sustain', 6), ('charitable', 6), ('puzzle', 6), ('settled', 6), ('disgust', 6), ('unsafe', 6), ('sham', 6), ('despair', 6), ('rebuke', 6), ('disappoint', 6), ('queasy', 6), ('depress', 6), ('delight', 6), ('aggravated', 5), ('embarrass', 5), ('frantic', 5), ('grim', 5), ('negligence', 5), ('reject', 5), ('revolt', 5), ('atrocious', 5), ('rejoice', 5), ('hostile', 5), ('neglected', 5), ('laughable', 5), ('envy', 5), ('elicit', 5), ('attraction', 5), ('moderately', 5), ('tortured', 5), ('annoy', 5), ('rejection', 5), ('temper', 5), ('compassionate', 5), ('mourning', 5), ('entertainment', 5), ('congratulate', 5), ('provoke', 5), ('strained', 5), ('berate', 5), ('tense', 5), ('lust', 5), ('turmoil', 4), ('aggravating', 4), ('lone', 4), ('loneliness', 4), ('terrorist', 4), ('coveted', 4), ('enthusiasm', 4), ('scold', 4), ('aggression', 4), ('compound', 4), ('distressing', 4), ('bid', 4), ('angrily', 4), ('fond', 4), ('depressant', 4), ('worship', 4), ('thrill', 4), ('tendency', 4), ('grieving', 4), ('sticky', 4), ('propensity', 4), ('stimulant', 4), ('savor', 4), ('revolting', 4), ('jaundice', 4), ('continent', 4), ('scourge', 4), ('embarrassment', 4), ('astonishing', 4), ('desperation', 4), ('enraged', 4), ('ramp', 4), ('reliever', 4), ('stimulating', 4), ('agony', 4), ('anxiously', 4), ('assault', 4), ('tormented', 4), ('craze', 4), ('disturbed', 4), ('licking', 4), ('fermentation', 4), ('frighten', 4), ('crabby', 4), ('enjoyment', 4), ('insecurity', 4), ('negligent', 3), ('elated', 3), ('disdain', 3), ('envious', 3), ('galling', 3), ('rack', 3), ('gloom', 3), ('bliss', 3), ('warmth', 3), ('spicy', 3), ('isolate', 3), ('humiliating', 3), ('affection', 3), ('fussy', 3), ('desired', 3), ('merry', 3), ('loathing', 3), ('diverted', 3), ('brutality', 3), ('frenzy', 3), ('shocker', 3), ('annoyance', 3), ('harrowing', 3), ('triumph', 3), ('grouchy', 3), ('joyful', 3), ('optimism', 3), ('amusing', 3), ('stimulation', 3), ('contempt', 3), ('uneasy', 3), ('delirium', 3), ('detest', 3), ('excite', 3), ('amazement', 3), ('stimulated', 3), ('brat', 3), ('stupor', 3), ('stung', 3), ('isolating', 3), ('frustrate', 3), ('dismayed', 3), ('delirious', 3), ('hater', 3), ('regrets', 3), ('detached', 3), ('gratification', 2), ('infuriated', 2), ('scotch', 2), ('torturing', 2), ('savvy', 2), ('wounded', 2), ('teaser', 2), ('scandalous', 2), ('humiliation', 2), ('hopelessly', 2), ('nervously', 2), ('fright', 2), ('terrify', 2), ('rape', 2), ('jealousy', 2), ('tenacious', 2), ('incorporate', 2), ('bait', 2), ('jolly', 2), ('cutter', 2), ('wishful', 2), ('tending', 2), ('vindictive', 2), ('combative', 2), ('virulent', 2), ('abomination', 2), ('empathise', 2), ('hideous', 2), ('dun', 2), ('wretched', 2), ('astonish', 2), ('distasteful', 2), ('conjure', 2), ('hysteria', 2), ('teasing', 2), ('diss', 2), ('heartbreak', 2), ('exacerbating', 2), ('fervor', 2), ('satisfaction', 2), ('stamp', 2), ('upbeat', 2), ('carelessness', 2), ('gloating', 2), ('furiously', 2), ('woefully', 2), ('jittery', 2), ('fondly', 2), ('obscure', 2), ('heartache', 2), ('yearn', 2), ('potty', 2), ('protagonist', 2), ('respite', 2), ('detriment', 2), ('feign', 2), ('plethora', 2), ('dismal', 2), ('thrilling', 2), ('satisfy', 2), ('lovable', 2), ('torturous', 2), ('savagery', 2), ('gloomy', 2), ('simulate', 2), ('weakened', 2), ('pitiful', 2), ('thriller', 2), ('relish', 2), ('bonk', 2), ('chagrin', 2), ('eagerly', 2), ('enthusiastic', 2), ('entertained', 2), ('agonist', 2), ('hopelessness', 2), ('craved', 2), ('vengeful', 1), ('unattended', 1), ('savory', 1), ('quarantined', 1), ('infuriate', 1), ('uptight', 1), ('displeasure', 1), ('mortifying', 1), ('thorn', 1), ('adoration', 1), ('distressed', 1), ('joyfully', 1), ('venom', 1), ('irritant', 1), ('aghast', 1), ('sprinkle', 1), ('humiliated', 1), ('foiled', 1), ('stir', 1), ('ecstasy', 1), ('cull', 1), ('commiseration', 1), ('irritate', 1), ('exasperated', 1), ('yearning', 1), ('usurious', 1), ('blithely', 1), ('uplift', 1), ('wildness', 1), ('irritation', 1), ('cheerful', 1), ('elating', 1), ('apprehensive', 1), ('charmed', 1), ('dismay', 1), ('boldness', 1), ('nark', 1), ('gloat', 1), ('crow', 1), ('fain', 1), ('spunk', 1), ('hullabaloo', 1), ('jealously', 1), ('caustic', 1), ('crabbed', 1), ('injure', 1), ('vibrate', 1), ('fulfil', 1), ('glum', 1), ('enormity', 1), ('resentment', 1), ('jubilant', 1), ('peeved', 1), ('agonize', 1), ('elation', 1), ('gusto', 1), ('Colony', 1), ('baffle', 1), ('pestered', 1), ('tender', 1), ('rejoicing', 1), ('prevail', 1), ('malaise', 1), ('benevolent', 1), ('riled', 1), ('amuse', 1), ('sorrow', 1), ('blockade', 1), ('mortified', 1), ('bereft', 1), ('reprimand', 1), ('grumpiness', 1), ('gravel', 1), ('hostility', 1), ('hapless', 1), ('shudder', 1), ('bitterness', 1), ('lonesome', 1), ('dishonor', 1), ('astound', 1), ('throb', 1), ('displeased', 1), ('attract', 1), ('commiserate', 1), ('aroused', 1), ('contemptuous', 1), ('sicken', 1), ('unrestrained', 1), ('colonizer', 1), ('nervousness', 1), ('restlessness', 1), ('disliked', 1), ('unrest', 1), ('apprehension', 1), ('foil', 1), ('drab', 1), ('smitten', 1), ('jubilee', 1), ('merriment', 1), ('repent', 1), ('energise', 1), ('letdown', 1), ('thwarted', 1), ('adoring', 1), ('disposed', 1), ('sympathise', 1), ('quenched', 1), ('energize', 1), ('indignant', 1), ('terrorize', 1), ('revel', 1), ('edgy', 1), ('astonished', 1), ('amusement', 1), ('bitterly', 1), ('spew', 1), ('wallow', 1), ('despised', 1), ('vexatious', 1), ('joyously', 1), ('wrath', 1), ('bore', 1), ('precaution', 1), ('anguish', 1), ('violate', 1), ('invoke', 1), ('torment', 1), ('lovingly', 1), ('somber', 1), ('repellent', 1), ('agonising', 1), ('jumpy', 1), ('middling', 1), ('diverting', 1), ('lightness', 1), ('tingle', 1), ('exhilarating', 1), ('dejected', 1), ('infliction', 1), ('sedative', 1), ('easing', 1), ('fondness', 1), ('joyous', 1), ('banter', 1), ('hearty', 1), ('discernment', 1)]\n"
     ]
    }
   ],
   "source": [
    "emojo_dict = {}\n",
    "\n",
    "for tweet in tweets.text:\n",
    "    tweet = prep.replace_hashtags_URL_USER(tweet, mode_URL=\"delete\", mode_Mentions=\"delete\")\n",
    "    tweet = prep.tokenize(tweet)\n",
    "    \n",
    "    for word in tweet:\n",
    "        for emot in Emotions.emotions_full_list:\n",
    "            \n",
    "            if emot == word: \n",
    "                if word in emojo_dict: emojo_dict[emot] += 1\n",
    "                else : emojo_dict[emot] = 1\n",
    "                    \n",
    "sorted_y = sorted(emojo_dict.items(), key=operator.itemgetter(1))[::-1]\n",
    "print(sorted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11218, 39)\n"
     ]
    }
   ],
   "source": [
    "emot_tweets = tweets[tweets[\"emotion\"] == True]\n",
    "print(emot_tweets.shape)\n",
    "emot_tweets.to_parquet(\"/home/adrian/PhD/Data/Tweets20190708/matching-tweets_diab_noRT-noBots_personal_noJokes_locationUS_geoCityCodeNotNull_emotions.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
